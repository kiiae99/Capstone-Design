# Capstone Design 2023-1

# Backchannel Prediction
* Minki Kim
* Minjae Kim

## Overview
<p align="center">
<img width="600" alt="image" src="https://github.com/kiiae99/Capstone-Design/assets/86785673/e26f7e5f-a84a-4d2d-9992-98e9222775ee">
</p>

* BERT/KoBERT와 HuBERT, MultiMAE를 활용한 Backchannel Prediction Model

## Conclusion
<p align="center">
<img width="800" alt="image" src="https://github.com/kiiae99/Capstone-Design/assets/86785673/7399f3c6-8b74-450b-9c44-77226faee2f1">
</p>



## References
* “BPM_MT: Enhanced Backchannel Prediction Model using Multi-Task Learning” [Jang et al,. EMNLP’21]
* “OH, JEEZ! OR UH-HUH? A LISTENER-AWARE BACKCHANNEL PREDICTOR ON ASR TRANSCRIPTIONS” [Ortega et al,. ICASSP’20]
* “MultiMAE: Multi-modal Multi-task Masked Autoencoders” [Roman et al,. ECCV'22]

## Reports
* [BC_최종보고서.pdf](https://github.com/kiiae99/Capstone-Design/files/11781781/BC_.pdf)
